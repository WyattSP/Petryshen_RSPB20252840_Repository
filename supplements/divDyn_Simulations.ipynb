{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad9c433",
   "metadata": {},
   "source": [
    "# Simulate Dynamics for example with SQS\n",
    "\n",
    "1) Simulate neutral and species-model dynamics\n",
    "2) Calculate SQS metrics in R with SQSAnalysis.R\n",
    "3) Import results into notebook and conduct Haar fluctuation analysis and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1054e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Library Import == \n",
    "# Set directrory to src\n",
    "# Run a simulation and save the output matrix.\n",
    "src_paths = \"../src/\"\n",
    "\n",
    "# Set paths \n",
    "import os\n",
    "import sys\n",
    "os.chdir(src_paths)\n",
    "sys.path.append(os.getcwd()) \n",
    "\n",
    "# From src\n",
    "## Diversity Metric Functions\n",
    "from diversityMetrics import *\n",
    "import divDynFunctions\n",
    "from pareto import *\n",
    "import untbPython\n",
    "import samplingFunctions\n",
    "import divDynFunctions\n",
    "## Haar Fluctuation Analysis Functions\n",
    "from haarFluctuationAnalysis import Haar_hebert\n",
    "from crossHaarCorrelation import CHFC\n",
    "\n",
    "# Other Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from numba import njit, set_num_threads\n",
    "\n",
    "# Depositional Model\n",
    "def depositional_model_time(cutoffs, max_time, deposition_integration):\n",
    "\n",
    "    # Externally Set Parameters\n",
    "    cutoff = cutoffs # This is what we will be setting for the pareto_cutoff\n",
    "\n",
    "    # Internally Set Parameters\n",
    "    gamma = 0.4 # Shape parameter used in Schumer and Jerolmack 2009\n",
    "    xmin = 1 # minimum hiatus duration (year); using integer values so must be int\n",
    "    deposition_rate = 1000  # cm/yr\n",
    "    deposition_duration = deposition_integration  # 1000 years\n",
    "    deposition_thickness = deposition_rate * deposition_duration  # deposition = 10 cm\n",
    "    max_time = max_time  # max total simulated time in kyr (stop condition); Base on selection from UNTB simulation\n",
    "\n",
    "    # Set Save Directories\n",
    "    times = [0]\n",
    "    elevation = [0]\n",
    "    obs_record =[]\n",
    "    t = 0\n",
    "    s = 0\n",
    "    step = 0\n",
    "\n",
    "    while t < max_time:\n",
    "        # Setting the hiatuses\n",
    "        while True:\n",
    "            hiatus = rpareto(n=1, lam=gamma, a=xmin).astype(int)[0]\n",
    "            if hiatus <= cutoff:\n",
    "                break\n",
    "\n",
    "        # Check if next step would exceed max_time\n",
    "        if t + hiatus + deposition_duration > max_time:\n",
    "            break \n",
    "\n",
    "        # Record dynamics within step\n",
    "        t += hiatus\n",
    "        obs_record.extend([False] * hiatus)  # Append erosion / nondeposition\n",
    "        t += deposition_duration\n",
    "        obs_record.extend([True] * deposition_duration)  # Append deposition\n",
    "        s += deposition_thickness\n",
    "        times.append(t)\n",
    "        elevation.append(s)\n",
    "        step += 1\n",
    "\n",
    "    # Will return up to the while statement\n",
    "    return np.asarray(obs_record), np.asarray(times), np.asarray(elevation)\n",
    "\n",
    "# Neutral Model\n",
    "# Redefintion of UNTB function to include actual number of mutations per individual time step\n",
    "@njit\n",
    "def untb_Hankin_Phylo_V2(initial_population, mutation_probability, death_rate, generations, keep = False):\n",
    "    # Initalize\n",
    "    pop_size = len(initial_population) # Size of Jm\n",
    "    \n",
    "    # Allocate output matrix\n",
    "    out_matrix = np.full(shape = (generations, pop_size), fill_value = np.nan)    \n",
    "    a = initial_population.copy()\n",
    "    out_matrix[0,:] = a # Time 1 is initial population\n",
    "\n",
    "    # Speciation Tracker\n",
    "    ansector = np.full(shape = (generations, death_rate), fill_value = np.nan)    \n",
    "    descendent = np.full(shape = (generations, death_rate), fill_value = np.nan)   \n",
    "\n",
    "    # Tracker number of new mutations\n",
    "    total_mutations = [0]\n",
    "\n",
    "    # Max Species Tracker\n",
    "    max_species_id = np.max(a)\n",
    "\n",
    "    # Simulate\n",
    "    for i in range(1, generations):\n",
    "    \n",
    "        died = np.random.choice(pop_size, death_rate, replace = False) # index position of deaths\n",
    "        mutated = np.random.uniform(0.0, 1, size=len(died)) < mutation_probability # probability new mutation arises\n",
    "        n_mutations = np.sum(mutated) # new species\n",
    "        n_deaths = np.sum(~mutated) # replaced species\n",
    "        total_mutations.append(n_mutations)\n",
    "\n",
    "        if n_deaths > 0:\n",
    "            a[died[~mutated]] = np.random.choice(a, n_deaths, replace = True)\n",
    "        if n_mutations > 0:\n",
    "            new_species = np.arange(1, n_mutations + 1) + max_species_id \n",
    "            max_species_id += n_mutations\n",
    "\n",
    "            ansector[i,0:n_mutations] = a[died[mutated]]\n",
    "            a[died[mutated]] = new_species \n",
    "            descendent[i,0:n_mutations] = new_species\n",
    "            \n",
    "        out_matrix[i,:] = a\n",
    "        \n",
    "    return out_matrix, ansector, descendent, np.asarray(total_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b588754",
   "metadata": {},
   "outputs": [],
   "source": [
    "## == Define Parameters ==\n",
    "num_runs = 1\n",
    "\n",
    "# Define Parameter Grid\n",
    "pareto_cutoff = [10, 100, 1000]\n",
    "deposition_integration = [1, 10, 100]\n",
    "param_grid = list(product(pareto_cutoff, deposition_integration))\n",
    "\n",
    "## == Begin Simulations ==\n",
    "sim_length = 12000 # Running the simulation for 50,000 time steps\n",
    "J = 100 # Community size \n",
    "v = 0.05 # Speciation rate\n",
    "d = 10\n",
    "cutoffs = np.array([1000])\n",
    "model_steps = np.max(cutoffs) + sim_length # Extending the simulation time\n",
    "time_v = np.arange(cutoffs[0], cutoffs[0] + sim_length) - cutoffs[0]\n",
    "\n",
    "# Simulate Neutral Ecology\n",
    "expanded_community = np.repeat(1,J)\n",
    "untb_results, ancs, desc, _ = untb_Hankin_Phylo_V2(expanded_community, mutation_probability = v, death_rate = d, generations = model_steps, keep = False)\n",
    "\n",
    "# Make sure we have a simulation that doesn't go extinct\n",
    "species_list_all = np.arange(1, np.max(untb_results)+1, dtype = np.int64)\n",
    "set_num_threads(8) # Set thread number\n",
    "spec_dyn = samplingFunctions.retrieve_species_dynamics_numba(untb_results, species_id = species_list_all)\n",
    "\n",
    "## == Metrics for the perfectly sampled community using second-for-third == \n",
    "# Ideal Haar fluctuations for the community \n",
    "cut = cutoffs[0]\n",
    "# Bias the output\n",
    "test_spec = np.array(spec_dyn.copy(), dtype=np.int64)\n",
    "presence = test_spec[cut:] # Discard burn-in period\n",
    "# Get metrics\n",
    "# Filter out time steps you will not observe\n",
    "occ_list = convert_to_dictionary(presence)\n",
    "\n",
    "# Diversity \n",
    "dynMat = divDynFunctions.binnedToExpandedFad(occ_list)\n",
    "metricMatrix = divDynFunctions.counts(dynMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metricMatrix\n",
    "# Example if it's an array\n",
    "df = pd.DataFrame(dynMat)\n",
    "df.to_csv(\"./data/ForDivDyn/dynMat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79811416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation with cutoff=1000, dep=10\n",
      "Simulations complete.\n"
     ]
    }
   ],
   "source": [
    "## == Define Parameters ==\n",
    "num_runs = 1\n",
    "\n",
    "# Define Parameter Grid\n",
    "pareto_cutoff = [1000]\n",
    "deposition_integration = [10]\n",
    "param_grid = list(product(pareto_cutoff, deposition_integration))\n",
    "\n",
    "## == Begin Simulations ==\n",
    "sim_length = 12000 # Running the simulation for 50,000 time steps\n",
    "J = 100 # Community size \n",
    "v = 0.05 # Speciation rate\n",
    "d = 10\n",
    "cutoffs = np.array([1000])\n",
    "model_steps = np.max(cutoffs) + sim_length # Extending the simulation time\n",
    "time_v = np.arange(cutoffs[0], cutoffs[0] + sim_length) - cutoffs[0]\n",
    "\n",
    "# Simulate Neutral Ecology\n",
    "expanded_community = np.repeat(1,J)\n",
    "untb_results, ancs, desc, _ = untb_Hankin_Phylo_V2(expanded_community, mutation_probability = v, death_rate = d, generations = model_steps, keep = False)\n",
    "\n",
    "# Make sure we have a simulation that doesn't go extinct\n",
    "species_list_all = np.arange(1, np.max(untb_results)+1, dtype = np.int64)\n",
    "set_num_threads(8) # Set thread number\n",
    "spec_dyn = samplingFunctions.retrieve_species_dynamics_numba(untb_results, species_id = species_list_all)\n",
    "\n",
    "\n",
    "## == Run Model == ##\n",
    "\n",
    "# Run intial simulation for data before aggregation\n",
    "# Set desktop path\n",
    "results_summary = []\n",
    "\n",
    "for cutoff, depositional_steps in param_grid:\n",
    "    save_comb = []\n",
    "\n",
    "    for run_id in range(1, num_runs + 1):\n",
    "        try:\n",
    "            print(f\"Running simulation with cutoff={cutoff}, dep={depositional_steps}\")\n",
    "\n",
    "            ###\n",
    "            # Retrive UNTB outputs\n",
    "            test_spec = np.array(spec_dyn.copy(), dtype=np.int64)\n",
    "            presence = test_spec[cutoffs[0]:]\n",
    "            occ_list = convert_to_dictionary(presence[time_v,:])\n",
    "            o_div = [len(i) for i in occ_list]\n",
    "\n",
    "            #### -------------------------------------\n",
    "            # Run depositional model\n",
    "            obs_record, times, elevation = depositional_model_time(cutoffs = cutoff, max_time = 12000, deposition_integration = depositional_steps)\n",
    "\n",
    "            # Bias the output\n",
    "            # Set all arrays to empty if erosion occurs\n",
    "            for i in range(len(obs_record)):\n",
    "                state = obs_record[i]\n",
    "                if state == False:\n",
    "                    occ_list[i] = np.array([])\n",
    "\n",
    "            # Filter based on hiatuses and plot\n",
    "            o_div_filt = [len(i) for i in occ_list]\n",
    "            non_zero_values = [val for val in o_div_filt if val > 0]\n",
    "            #min_non_zero = min(non_zero_values) if non_zero_values else 0\n",
    "\n",
    "            # Combine elements of array based on boundaries\n",
    "            new_occ_list = []\n",
    "            for i in range(len(times) - 1):\n",
    "                agg_list = occ_list[int(times[i]):int(times[i+1])]\n",
    "                if len(agg_list) <= 1:\n",
    "                    new_occ_list.append(np.array(list(agg_list)))\n",
    "                else:\n",
    "                    aggregated_beds = np.unique(np.concatenate(agg_list)) \n",
    "                    new_occ_list.append(aggregated_beds)\n",
    "\n",
    "            # Diversity Metrics\n",
    "            # Diversity \n",
    "            dynMat = divDynFunctions.binnedToExpandedFad(new_occ_list)\n",
    "\n",
    "            # Map Times \n",
    "            mid_point_times = (times[:-1] + np.diff(times)/2)\n",
    "\n",
    "            mapped_values = mid_point_times[dynMat[:, 1]]\n",
    "            arr_new = np.column_stack((dynMat, mapped_values))\n",
    "\n",
    "            # Save metricMatrix\n",
    "            # Example if it's an array\n",
    "            save_name = f\"sim_{cutoff}_{depositional_steps}\"\n",
    "            df = pd.DataFrame(arr_new)\n",
    "            df.to_csv(f\"./data/ForDivDyn/{save_name}.csv\", index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error for Pareto cutoff={cutoff}, depositional steps = {depositional_steps}, run={run_id}: {e}\")\n",
    "\n",
    "print(f\"Simulations complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
